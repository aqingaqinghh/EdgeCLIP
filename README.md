# EdgeCLIP: Injecting Edge-Awareness into Visual-Language Models for Zero-Shot Semantic Segmentation

ğŸ“¢Thanks for your interest in our work!

Jiaxiang Fang, Shiqiang Ma, Guihua Duan, Fei Guo, Shengfeng He

![Alt text](./model.png)


> **Abstract:** Effective segmentation of unseen categories in zero-shot semantic segmentation is hindered by models' limited ability to interpret edges in unfamiliar contexts. In this paper, we propose EdgeCLIP, which addresses this by integrating CLIP with explicit edge-awareness. Based on the premise that edge variation patterns are similar across both seen and unseen objects, EdgeCLIP introduces the Contextual Edge Sensing module. This module accurately discerns and utilizes edge information, which is crucial in complex border areas where conventional models struggle. Further, our Text-Guided Dense Feature Matching strategy precisely aligns text encodings with corresponding visual edge features, effectively distinguishing them from background edges. This strategy not only optimizes the training of CLIP's image and text encoders but also leverages the intrinsic completeness of objects, enhancing the model's ability to generalize and accurately segment objects in unseen classes. EdgeCLIP significantly outperforms the current state-of-the-art method, achieving a deep impressive margin of **5.8%** and **17.5%** on PASCAL-5<sup>i</sup> and COCO-20<sup>i</sup> datasets respectively.
   
## Installation

### ğŸ“˜ Environment
   - python == 3.9.13

   - torch == 1.13.0

   - torchvision == 0.14.0 

   - cuda == 11.6


### ğŸ“ Data preparation
Download the PASCAL-5<sup>i</sup> and COCO-20<sup>i</sup> datasets following  [HERE](https://github.com/juhongm999/hsnet).  


The ./datasets/ folder should have the following hierarchy:


    â””â”€â”€ datasets/
        â”œâ”€â”€ VOC2012/            # PASCAL VOC2012 devkit
        â”‚   â”œâ”€â”€ Annotations/
        â”‚   â”œâ”€â”€ ImageSets/
        â”‚   â”œâ”€â”€ ...
        â”‚   â”œâ”€â”€ SegmentationClassAug/
        â”œâ”€â”€ COCO2014/           
        â”‚   â”œâ”€â”€ annotations/
        â”‚   â”‚   â”œâ”€â”€ train2014/  # (dir.) training masks
        â”‚   â”‚   â”œâ”€â”€ val2014/    # (dir.) validation masks 
        â”‚   â”‚   â””â”€â”€ ..some json files..
        â”‚   â”œâ”€â”€ train2014/
        â”‚   â”œâ”€â”€ val2014/
        

## ğŸ“š References

This repository owes its existence to the exceptional contributions of other projects:

* DenseCLIP: https://github.com/raoyongming/DenseCLIP
* SAZS: https://github.com/Liuxinyv/SAZS?tab=readme-ov-file

Many thanks to their invaluable contributions.







